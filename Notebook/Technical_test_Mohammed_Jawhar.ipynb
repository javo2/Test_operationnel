{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf1f0de-c116-42cc-a0f2-fd99702b0b72",
   "metadata": {},
   "source": [
    "### <p style=\"text-align:left\"><span style=\"color:green\">Importing Required `Libraries`</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662e0e2c-901a-4c57-a586-f0768e0179fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contractions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01men\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m English\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01men\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstop_words\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STOP_WORDS\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontractions\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Plotting libraries :\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contractions'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing necessary libraries and functions :\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "# Text processing libraries :\n",
    "import gensim \n",
    "import re # Regular Expression library\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.tokenize import word_tokenize # Tokenizaion \n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import contractions\n",
    "\n",
    "# Plotting libraries :\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn : \n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9798366-5430-4e2c-bf48-4485328fbd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a5fa7-452e-4d32-b833-9829ee5ec862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization libraries:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Other libraries:\n",
    "#from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Data science imports:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    BaggingRegressor,\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    median_absolute_error\n",
    ")\n",
    "\n",
    "# Configure pandas to display all columns:\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Render figures directly in the notebook:\n",
    "%matplotlib inline\n",
    "\n",
    "# Render higher resolution images:\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Ignore warning messages:\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d636c76-5447-4c5b-95eb-9e4ac8ebc0ab",
   "metadata": {},
   "source": [
    "### <p style=\"text-align:left\"><span style=\"color:green\">Reading the `CSV File`</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735211ee-d431-438b-807a-693e160cb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('../data/tweets dataset.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da879889-707f-4151-9d55-1a0b497365d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d970c-a644-4dac-8680-add983d13938",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed764600-8be1-4788-967a-ec66cf80816b",
   "metadata": {},
   "source": [
    "The dataset contains 9093 records and consists in three columns:\n",
    "\n",
    "* **tweet_text :** The tweet's content\n",
    "* **emotion_in_tweet_is_directed_at :** The brand mentioned in the tweet\n",
    "* **is_there_an_emotion_directed_at_a_brand_or_product :** The emotion/neutrality expressed in the tweet   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0aac3-55fa-47f3-95f4-117a87651351",
   "metadata": {},
   "source": [
    "### <p style=\"text-align:left\"><span style=\"color:green\">Exploring the dataset</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d410b62-9899-47f7-92e7-77e101c28049",
   "metadata": {},
   "source": [
    "Let us first check wether our data is cleaned and if there is any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2293305-f9e9-4d3d-b48d-3e5b858849bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The data columns contain the following missing values: \")\n",
    "tweets_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad632d51-64f6-4fec-a9c5-84b45a0eb43f",
   "metadata": {},
   "source": [
    "As we can see, there is a missing tweet, we will delete it later since it is not relevant in our case. \n",
    "There are also 5802 missing values out of 9093 in the *emotion_in_tweet_is_directed_at* column, we will implement an approach to deal with them later since they represent an important percentage of our data which could bring us significant insights and help us in the analysis and visualization part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26960b2f-0a30-4d6c-915c-a5d50615a36b",
   "metadata": {},
   "source": [
    "In order to analyze the tweet's structure and find more about its relationship with the column *emotion_in_tweet_is_directed_at*, we can display fully  some samples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cc551-ec0a-4297-80ae-d454d1f775bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df  =  tweets_df.sample(n = 200)\n",
    "for i in range(len(random_df)):\n",
    "    print(random_df.iloc[i][0])\n",
    "    print(random_df.iloc[i][1])\n",
    "    print('----------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e93900-b5be-4ce5-b26a-02617fbe373b",
   "metadata": {},
   "source": [
    "By observing and analyzing the above result , we can make some preliminary hypotheses: \n",
    "* The tweets don't follow a standard structure, they start sometimes with a mention, other times with an hashtag , and even with simple words directly.\n",
    "* The brands mentioned in the tweets aren't always simly identifiable,m especially when they are not preceded with an hashtag or a mention, which would make the task of replacing the missing value of the brands comumn harder .\n",
    "* The tweets contain some insignificant words/ characters, which are not useful and will be deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d00a05-906f-4ea7-a4a1-50a4c227d387",
   "metadata": {},
   "source": [
    "Let's take a look at our target column which is *is_there_an_emotion_directed_at_a_brand_or_product*, and explore the different classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d7301-b1ab-41ba-803e-77c0e9ea35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d08c7-b377-4bc1-8385-cb2641d300f0",
   "metadata": {},
   "source": [
    "It seems that we have 4 classes that rate the emotion expressed in the tweets. howevwr this classes are not well balances, especially the \"I can't tell\" one : there are so few of these values in comparison with the rest of the classes, and since it won't be so useful for our purpose, we will delete it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7fe8b-6d6e-4105-9831-1575543c0f8a",
   "metadata": {},
   "source": [
    "### <p style=\"text-align:left\"><span style=\"color:green\">Cleaning and preprocessing</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1430c-8212-46b4-a797-14e9b7287b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.rename(columns={'tweet_text': 'tweets', 'emotion_in_tweet_is_directed_at': 'brands', 'is_there_an_emotion_directed_at_a_brand_or_product': 'emotions'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062268c4-514c-4e05-933f-317379e2a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_indexes = tweets_df[(tweets_df['emotions'] == \"I can't tell\")].index\n",
    "tweets_df.drop(drop_indexes, inplace = True)\n",
    "tweets_df.dropna(subset = ['tweets'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b082d6-9890-45b6-9792-782c0a820782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900e888-5994-4cd4-9896-710f75e3a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['emotions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891b665-d220-40bf-ac8f-4c0d20f5a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['emotions'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f3675-f6bc-410b-9742-4ad863f651e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,5))\n",
    "# Create the classes percentages\n",
    "percentages = tweets_df['emotions'].value_counts(normalize = True)\n",
    "\n",
    "# Create bar plot with stacked bars\n",
    "plt.bar(0, percentages[0], label='No Emotion')\n",
    "plt.bar(0, percentages[1], bottom=percentages[0], label='Positive')\n",
    "plt.bar(0, percentages[2], bottom=sum(percentages[:2]), label='Negative')\n",
    "plt.legend(bbox_to_anchor=(1.7, 0.5), loc=\"center right\")\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel('Emotions')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of Emotion Classes')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4563c-4dc2-4f3a-8e2f-3329c76a37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the class percentages\n",
    "percentages = tweets_df['emotions'].value_counts(normalize=True)\n",
    "\n",
    "# Set the style to use Seaborn's color palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a pie chart (circle plot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(percentages, labels=percentages.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"deep\"))\n",
    "\n",
    "# Set the title\n",
    "plt.title('Percentage of Emotion Classes')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa91b5-d1b4-4c74-b546-cb3f2fe775df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['brands'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf376c76-1dec-4598-9e79-b96590a34f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_emotions = tweets_df.groupby(['emotions'])['brands'].value_counts()\n",
    "grouped_by_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d271847-76bc-4468-842d-9ce9c6c9a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_emotions['Positive emotion'].sort_values().plot(kind='barh', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77ef3b-1f1c-48bb-b211-21c8d4eec1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_emotions['Negative emotion'].sort_values().plot(kind='barh', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44e536-0e7f-44cc-9d1a-abb38bf0b991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743db54-baa5-4d31-b847-7e63710d6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'brands' and 'emotions' and calculate the count of each combination\n",
    "grouped = tweets_df.groupby(['brands', 'emotions']).size().unstack()\n",
    "\n",
    "# Calculate the total count of each brand\n",
    "total_counts = grouped.sum(axis=1)\n",
    "\n",
    "# Calculate the percentages\n",
    "percentage_data = grouped.div(total_counts, axis=0) * 100\n",
    "\n",
    "# Sort the DataFrame by the percentage of positive emotion in descending order\n",
    "sorted_percentage_data = percentage_data.sort_values(by='Positive emotion', ascending=False)\n",
    "\n",
    "# Create a stacked bar plot\n",
    "ax = sorted_percentage_data.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "ax.set_xlabel('Brand')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Percentage of Positive Emotions for Each Brand (Sorted)')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title='Emotions', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c55a8b-b1e3-4b65-ba19-90c5d2598525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc9cdeb-c53d-487e-a4a4-7f1d3e502994",
   "metadata": {},
   "source": [
    "### 5️⃣  `Data Preprocessing ` :\n",
    "\n",
    "> Our data generally comes from a variety of different sources and is often in a variety of different formats. For this reason, cleaning our raw data is an essential part of preparing our dataset. However, cleaning is not a simple process, as textual data often contains redundant and/or repetitive words.\n",
    "\n",
    "> Before training the model, we will perform various pre-processing steps on the dataset such as: \n",
    ">- Converting the text document to lowercase for better generalization.\n",
    ">- Removing stop words.\n",
    ">- Removing emojis. \n",
    ">- Removing of mentions & hastags.\n",
    ">- Removal of numbers.\n",
    ">- Removal of whitespaces.\n",
    ">- Cleaning the ponctuation (to reduce unnecessary noise from the dataset).\n",
    ">- Removing the repeating characters from the words along with removing the URLs/hyperlinks as they do not have any significant importance. <br>                          \n",
    "and much more, we will see this in detail later...\n",
    "\n",
    "> We will then performe:\n",
    ">- **`Stemming`** : reducing the words to their derived stems.\n",
    ">- **`Lemmatization`** : reducing the derived words to their root form known as lemma for better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed19bd2-0a0b-49a4-88dc-1c9892a51d64",
   "metadata": {},
   "source": [
    "> - **`Lowering Case`**:\n",
    "\n",
    "Lowering case is very imprtant since it allows us to make words with same value equal. This will be very useful to reduce the dimensions of our vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98791307-cd8b-4f72-bd82-57e52249ea8f",
   "metadata": {},
   "source": [
    "> - **`Removal of Mentions`**:\n",
    "\n",
    "In social media, Mentions are used to call/mention another user into our post. Generally, mentions don't have an added value to our model. So we will remove them.\n",
    "\n",
    "A mention has a special pattern: **@UserName** or  **#UserName**, So we will remove all string which starts with @"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d2a70-24ab-4bcd-b188-df757216b5a5",
   "metadata": {},
   "source": [
    " > - **`Removal of Special Characters`**:\n",
    " \n",
    "Special characters are every where, since we have punctuation marks in our tweets. In order to treat, for example, **hello!** and **hello** in the same way.  we have to remove the punctuation mark **!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eae739-f87d-4c63-a6b6-93c358d075e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def RemoveMentions(text):\n",
    "    text_ = re.sub(r\"@\\S+\", \"\", text)\n",
    "    text_ = re.sub(r\"#\\S+\", \"\", text)\n",
    "    return text_\n",
    "\n",
    "\n",
    "# Defining a list containing punctuation signs of english :\n",
    "punctuations_list = string.punctuation\n",
    "\n",
    "## Defining that will be applied to our datset : \n",
    "def RemovePunctuations(text):\n",
    "    transformator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(transformator)\n",
    "\n",
    "stopWords = stopwords.words('english')\n",
    "\n",
    "\n",
    "def RemoveLinks(text):\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "def RemoveNumbers(text):       \n",
    "    return re.sub(r\"[0-9]+\", \"\", text)\n",
    "\n",
    "def RemoveWhitespaces(text):\n",
    "    text=text.strip()  # Leading and trailing whitespaces are removed\n",
    "    return re.sub(r\" +\",\" \",text)\n",
    "\n",
    "def process(data):\n",
    "    data = data.str.lower()\n",
    "    data = data.apply(RemoveMentions)\n",
    "    data = data.apply(RemovePunctuations)\n",
    "    data = data.apply(lambda x: ' '.join([word for word in x.split() if (word not in stopWords) | (len(word)<=3)]))\n",
    "    data = data.apply(RemoveLinks)\n",
    "    data = data.apply(RemoveNumbers)\n",
    "    data = data.apply(RemoveWhitespaces)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc37df-73c7-4a47-8750-732c539bcc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweets_processed'] = process(tweets_df['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1112da-537b-47ae-a08e-3e65f28dbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480345d-eb4b-474d-8804-898998483d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
